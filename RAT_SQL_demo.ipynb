{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jsonnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5XSl9htBkFN"
      },
      "source": [
        "# # !conda create --name gap-text2sql python=3.7\n",
        "# # try to get the bare minimum to get a new conda env working\n",
        "# conda_path = ''\n",
        "# try:\n",
        "#     conda_path = !which conda\n",
        "# finally:\n",
        "#     print('')\n",
        "\n",
        "# if (len(conda_path) == 0):\n",
        "#     print('installing miniconda')\n",
        "#     !wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh && bash Miniconda3-4.5.4-Linux-x86_64.sh -bfp /usr/local\n",
        "#     !conda update conda -y -q\n",
        "#     !source /usr/local/etc/profile.d/conda.sh\n",
        "#     !conda init \n",
        "#     !conda install -n root _license -y -q\n",
        "# else:\n",
        "#     print('found miniconda')\n",
        "\n",
        "# conda_envs = !conda env list\n",
        "# res = [i for i in conda_envs if 'test36' in i]\n",
        "# if (len(res) == 0):\n",
        "#     print('not found test36 env', len(res))\n",
        "#     #!conda create --name gap-text2sql python=3.7\n",
        "# else:\n",
        "#     print('found test36 env', len(res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkwdPGECCJJ"
      },
      "source": [
        "# !source activate gap-text2sql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9iH8QUnDGe7",
        "outputId": "2e393816-53ea-4593-f7ec-228a5e9d9a1d"
      },
      "source": [
        "!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (703.8MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.0+cu101) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.5.0+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtAhYz7_DI9h",
        "outputId": "76bb7053-55a7-4848-b6e9-c470d385c2f3"
      },
      "source": [
        "!git clone https://github.com/awslabs/gap-text2sql"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gap-text2sql'...\n",
            "remote: Enumerating objects: 351, done.\u001b[K\n",
            "remote: Counting objects: 100% (351/351), done.\u001b[K\n",
            "remote: Compressing objects: 100% (246/246), done.\u001b[K\n",
            "remote: Total 351 (delta 108), reused 328 (delta 91), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (351/351), 272.31 KiB | 15.13 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU9LIy8WDvFw",
        "outputId": "ef847370-91bc-427e-bf16-0688e4a02ad8"
      },
      "source": [
        "cd gap-text2sql/rat-sql-gap/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gap-text2sql/rat-sql-gap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLLm3ALxD40y",
        "outputId": "f64b4b49-5e2f-444c-a5ec-f05fd8f2df1c"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 22.5MB/s \n",
            "\u001b[?25hCollecting jsonnet~=0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/a6/e69e38f1f259fcf8532d8bd2c4bc88764f42d7b35a41423a7f4b035cc5ce/jsonnet-0.14.0.tar.gz (253kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 29.7MB/s \n",
            "\u001b[?25hCollecting nltk~=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx~=2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.5.1)\n",
            "Collecting entmax\n",
            "  Downloading https://files.pythonhosted.org/packages/05/da/27fc966a4786e933778161644a1a1a228148b296d2059682799c4a8ecff8/entmax-1.0.tar.gz\n",
            "Collecting pyrsistent~=0.14.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/46/4e93ab8a379d7efe93f20a0fb8a27bdfe88942cc954ab0210c3164e783e0/pyrsistent-0.14.11.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 44.2MB/s \n",
            "\u001b[?25hCollecting bpemb~=0.2.11\n",
            "  Downloading https://files.pythonhosted.org/packages/57/90/8760eaa97c5a2f676f3f350fd43e79f8d9e4f9c42362c62f733e81e37d33/bpemb-0.2.12-py3-none-any.whl\n",
            "Collecting stanford-corenlp~=3.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/31/a9/695357743b55c08e74e46fe72579ca2a2559fa9b196d9f2035339af89b94/stanford_corenlp-3.9.2-py2.py3-none-any.whl\n",
            "Collecting torchtext~=0.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/bc/b28b9efb4653c03e597ed207264eea45862b5260f48e9f010b5068d64db1/torchtext-0.3.1-py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0->-r requirements.txt (line 1)) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 27.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk~=3.4->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk~=3.4->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx~=2.2->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyrsistent~=0.14.9->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bpemb~=0.2.11->-r requirements.txt (line 7)) (3.6.0)\n",
            "Collecting corenlp-protobuf>=3.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/78/93/cc40d521cf6635fffa400b62799ddc761159302643d400cee72bd910efa9/corenlp_protobuf-3.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext~=0.3.1->-r requirements.txt (line 9)) (1.5.0+cu101)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0->-r requirements.txt (line 1)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb~=0.2.11->-r requirements.txt (line 7)) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb~=0.2.11->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from corenlp-protobuf>=3.8.0->stanford-corenlp~=3.9.2->-r requirements.txt (line 8)) (3.12.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchtext~=0.3.1->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->corenlp-protobuf>=3.8.0->stanford-corenlp~=3.9.2->-r requirements.txt (line 8)) (57.0.0)\n",
            "Building wheels for collected packages: jsonnet, entmax, pyrsistent\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.14.0-cp37-cp37m-linux_x86_64.whl size=3320139 sha256=a269451d630c656f99528517eecb0af461dd76939e1749e8ab531de73470934c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/b7/83/985f0f758fbb34f14989a0fab86d18890d1cc5ae12f26967bc\n",
            "  Building wheel for entmax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for entmax: filename=entmax-1.0-cp37-none-any.whl size=11017 sha256=448ee365681a82725435cc9d9961ac5ae23e6b622bdd90f94c2308885af828c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/2c/4e/687c0abbeb16f906bd5fb8a9763e1cdd2b0d118ad55a4332f2\n",
            "  Building wheel for pyrsistent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrsistent: filename=pyrsistent-0.14.11-cp37-cp37m-linux_x86_64.whl size=96925 sha256=78967d02c89566466edf426c3899e2ef59cb64194fb2a3ab8249fcf539056bad\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/59/9a/a037b9b3c3e93d9275ea0aff9d6064400f372879dfdab01afe\n",
            "Successfully built jsonnet entmax pyrsistent\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers, jsonnet, nltk, entmax, pyrsistent, bpemb, corenlp-protobuf, stanford-corenlp, torchtext\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: pyrsistent 0.17.3\n",
            "    Uninstalling pyrsistent-0.17.3:\n",
            "      Successfully uninstalled pyrsistent-0.17.3\n",
            "  Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed bpemb-0.2.12 corenlp-protobuf-3.8.0 entmax-1.0 jsonnet-0.14.0 nltk-3.6.2 pyrsistent-0.14.11 sacremoses-0.0.45 sentencepiece-0.1.96 stanford-corenlp-3.9.2 tokenizers-0.8.0rc4 torchtext-0.3.1 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYLi_YFyD7-5",
        "outputId": "51b31b87-e432-436b-8f34-309a9f95c782"
      },
      "source": [
        "!python -c \"import nltk; nltk.download('stopwords'); nltk.download('punkt')\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RYkZKsEEija",
        "outputId": "88ed04bb-423a-4801-d9ca-fa204c30f4aa"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTn0W2EwEsLc",
        "outputId": "5b0ce55e-a7ca-40a6-f36c-7d29c6cebdc1"
      },
      "source": [
        "!gdown --id 1_AckYkinAnhqmRQtGsQgUKAnTHxxX5J0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_AckYkinAnhqmRQtGsQgUKAnTHxxX5J0\n",
            "To: /content/gap-text2sql/rat-sql-gap/spider.zip\n",
            "99.7MB [00:00, 115MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv9olS4EEwim",
        "outputId": "33afd84e-8c52-47e5-ace8-f64b166be14b"
      },
      "source": [
        "!unzip spider.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  spider.zip\n",
            "   creating: spider/\n",
            "   creating: spider/database/\n",
            "   creating: spider/database/customer_deliveries/\n",
            "  inflating: spider/database/customer_deliveries/schema.sql  \n",
            "  inflating: spider/database/customer_deliveries/customer_deliveries.sqlite  \n",
            "   creating: spider/database/allergy_1/\n",
            "  inflating: spider/database/allergy_1/schema.sql  \n",
            "  inflating: spider/database/allergy_1/allergy_1.sqlite  \n",
            "   creating: spider/database/company_office/\n",
            "  inflating: spider/database/company_office/schema.sql  \n",
            "  inflating: spider/database/company_office/company_office.sqlite  \n",
            "   creating: spider/database/device/\n",
            "  inflating: spider/database/device/schema.sql  \n",
            "  inflating: spider/database/device/device.sqlite  \n",
            "   creating: spider/database/phone_1/\n",
            "  inflating: spider/database/phone_1/schema.sql  \n",
            "  inflating: spider/database/phone_1/phone_1.sqlite  \n",
            "   creating: spider/database/cre_Doc_Control_Systems/\n",
            "  inflating: spider/database/cre_Doc_Control_Systems/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Control_Systems/cre_Doc_Control_Systems.sqlite  \n",
            "   creating: spider/database/imdb/\n",
            "  inflating: spider/database/imdb/schema.sql  \n",
            "  inflating: spider/database/imdb/imdb.sqlite  \n",
            "   creating: spider/database/decoration_competition/\n",
            "  inflating: spider/database/decoration_competition/decoration_competition.sqlite  \n",
            "  inflating: spider/database/decoration_competition/schema.sql  \n",
            "   creating: spider/database/customers_campaigns_ecommerce/\n",
            "  inflating: spider/database/customers_campaigns_ecommerce/schema.sql  \n",
            "  inflating: spider/database/customers_campaigns_ecommerce/customers_campaigns_ecommerce.sqlite  \n",
            "   creating: spider/database/car_1/\n",
            "   creating: spider/database/car_1/data_csv/\n",
            "  inflating: spider/database/car_1/data_csv/countries.csv  \n",
            "  inflating: spider/database/car_1/data_csv/car-makers.csv  \n",
            "  inflating: spider/database/car_1/data_csv/continents.csv  \n",
            "  inflating: spider/database/car_1/data_csv/model-list.csv  \n",
            "  inflating: spider/database/car_1/data_csv/README.CARS.TXT  \n",
            "  inflating: spider/database/car_1/data_csv/cars.desc  \n",
            "  inflating: spider/database/car_1/data_csv/car-names.csv  \n",
            "  inflating: spider/database/car_1/data_csv/cars-data.csv  \n",
            "  inflating: spider/database/car_1/annotation.json  \n",
            "  inflating: spider/database/car_1/car_1.sql  \n",
            "  inflating: spider/database/car_1/q.txt  \n",
            "  inflating: spider/database/car_1/car_1.json  \n",
            " extracting: spider/database/car_1/link.txt  \n",
            "  inflating: spider/database/car_1/car_1.sqlite  \n",
            "   creating: spider/database/roller_coaster/\n",
            "  inflating: spider/database/roller_coaster/schema.sql  \n",
            "  inflating: spider/database/roller_coaster/roller_coaster.sqlite  \n",
            "   creating: spider/database/entrepreneur/\n",
            "  inflating: spider/database/entrepreneur/schema.sql  \n",
            "  inflating: spider/database/entrepreneur/entrepreneur.sqlite  \n",
            "   creating: spider/database/insurance_policies/\n",
            "  inflating: spider/database/insurance_policies/schema.sql  \n",
            "  inflating: spider/database/insurance_policies/insurance_policies.sqlite  \n",
            "   creating: spider/database/cre_Drama_Workshop_Groups/\n",
            "  inflating: spider/database/cre_Drama_Workshop_Groups/schema.sql  \n",
            "  inflating: spider/database/cre_Drama_Workshop_Groups/cre_Drama_Workshop_Groups.sqlite  \n",
            "   creating: spider/database/voter_1/\n",
            "  inflating: spider/database/voter_1/voter_1.sqlite  \n",
            "   creating: spider/database/journal_committee/\n",
            "  inflating: spider/database/journal_committee/schema.sql  \n",
            "  inflating: spider/database/journal_committee/journal_committee.sqlite  \n",
            "   creating: spider/database/performance_attendance/\n",
            "  inflating: spider/database/performance_attendance/schema.sql  \n",
            "  inflating: spider/database/performance_attendance/performance_attendance.sqlite  \n",
            "   creating: spider/database/store_1/\n",
            "  inflating: spider/database/store_1/schema.sql  \n",
            "  inflating: spider/database/store_1/store_1.sqlite  \n",
            "   creating: spider/database/school_player/\n",
            "  inflating: spider/database/school_player/schema.sql  \n",
            "  inflating: spider/database/school_player/school_player.sqlite  \n",
            "   creating: spider/database/scientist_1/\n",
            "  inflating: spider/database/scientist_1/schema.sql  \n",
            "  inflating: spider/database/scientist_1/scientist_1.sqlite  \n",
            "   creating: spider/database/student_transcripts_tracking/\n",
            "  inflating: spider/database/student_transcripts_tracking/schema.sql  \n",
            "  inflating: spider/database/student_transcripts_tracking/student_transcripts_tracking.sqlite  \n",
            "   creating: spider/database/department_store/\n",
            "  inflating: spider/database/department_store/schema.sql  \n",
            "  inflating: spider/database/department_store/department_store.sqlite  \n",
            "   creating: spider/database/cre_Doc_Template_Mgt/\n",
            "  inflating: spider/database/cre_Doc_Template_Mgt/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Template_Mgt/cre_Doc_Template_Mgt.sqlite  \n",
            "   creating: spider/database/local_govt_in_alabama/\n",
            "  inflating: spider/database/local_govt_in_alabama/schema.sql  \n",
            "  inflating: spider/database/local_govt_in_alabama/local_govt_in_alabama.sqlite  \n",
            "   creating: spider/database/browser_web/\n",
            "  inflating: spider/database/browser_web/schema.sql  \n",
            "  inflating: spider/database/browser_web/browser_web.sqlite  \n",
            "   creating: spider/database/cre_Docs_and_Epenses/\n",
            "  inflating: spider/database/cre_Docs_and_Epenses/schema.sql  \n",
            "  inflating: spider/database/cre_Docs_and_Epenses/cre_Docs_and_Epenses.sqlite  \n",
            "   creating: spider/database/apartment_rentals/\n",
            "  inflating: spider/database/apartment_rentals/schema.sql  \n",
            "  inflating: spider/database/apartment_rentals/apartment_rentals.sqlite  \n",
            "   creating: spider/database/flight_4/\n",
            " extracting: spider/database/flight_4/sql.txt  \n",
            "  inflating: spider/database/flight_4/flight_4.sqlite  \n",
            " extracting: spider/database/flight_4/link.txt  \n",
            "   creating: spider/database/hospital_1/\n",
            "  inflating: spider/database/hospital_1/schema.sql  \n",
            "  inflating: spider/database/hospital_1/hospital_1.sqlite  \n",
            "   creating: spider/database/soccer_1/\n",
            "  inflating: spider/database/soccer_1/schema.sql  \n",
            "  inflating: spider/database/soccer_1/soccer_1.sqlite  \n",
            "   creating: spider/database/gymnast/\n",
            "  inflating: spider/database/gymnast/schema.sql  \n",
            "  inflating: spider/database/gymnast/gymnast.sqlite  \n",
            "   creating: spider/database/soccer_2/\n",
            "  inflating: spider/database/soccer_2/schema.sql  \n",
            "  inflating: spider/database/soccer_2/soccer_2.sqlite  \n",
            "   creating: spider/database/formula_1/\n",
            "  inflating: spider/database/formula_1/formula_1.sql  \n",
            "   creating: spider/database/formula_1/data_csv/\n",
            "  inflating: spider/database/formula_1/data_csv/status.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/qualifying.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/results.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/pitStops.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructors.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/lapTimes.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructorResults.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/circuits.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructorStandings.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/races.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/seasons.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/drivers.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/driverStandings.csv  \n",
            " extracting: spider/database/formula_1/formula_1.splite  \n",
            "  inflating: spider/database/formula_1/annotation.json  \n",
            "  inflating: spider/database/formula_1/formula_1.sqlite  \n",
            "   creating: spider/database/workshop_paper/\n",
            "  inflating: spider/database/workshop_paper/schema.sql  \n",
            "  inflating: spider/database/workshop_paper/workshop_paper.sqlite  \n",
            "   creating: spider/database/shop_membership/\n",
            "  inflating: spider/database/shop_membership/schema.sql  \n",
            "  inflating: spider/database/shop_membership/shop_membership.sqlite  \n",
            "   creating: spider/database/candidate_poll/\n",
            "  inflating: spider/database/candidate_poll/schema.sql  \n",
            "  inflating: spider/database/candidate_poll/candidate_poll.sqlite  \n",
            "   creating: spider/database/hr_1/\n",
            "  inflating: spider/database/hr_1/schema.sql  \n",
            "  inflating: spider/database/hr_1/hr_1.sqlite  \n",
            "   creating: spider/database/storm_record/\n",
            "  inflating: spider/database/storm_record/schema.sql  \n",
            "  inflating: spider/database/storm_record/storm_record.sqlite  \n",
            "   creating: spider/database/ship_mission/\n",
            "  inflating: spider/database/ship_mission/ship_mission.sqlite  \n",
            "  inflating: spider/database/ship_mission/schema.sql  \n",
            "   creating: spider/database/coffee_shop/\n",
            "  inflating: spider/database/coffee_shop/schema.sql  \n",
            "  inflating: spider/database/coffee_shop/coffee_shop.sqlite  \n",
            "   creating: spider/database/bike_1/\n",
            "  inflating: spider/database/bike_1/schema.sql  \n",
            "  inflating: spider/database/bike_1/bike_1.sqlite  \n",
            "   creating: spider/database/activity_1/\n",
            "  inflating: spider/database/activity_1/schema.sql  \n",
            "  inflating: spider/database/activity_1/activity_1.sqlite  \n",
            "   creating: spider/database/film_rank/\n",
            "  inflating: spider/database/film_rank/schema.sql  \n",
            "  inflating: spider/database/film_rank/film_rank.sqlite  \n",
            "   creating: spider/database/program_share/\n",
            "  inflating: spider/database/program_share/schema.sql  \n",
            "  inflating: spider/database/program_share/program_share.sqlite  \n",
            "   creating: spider/database/company_1/\n",
            "  inflating: spider/database/company_1/company_1.sqlite  \n",
            "  inflating: spider/database/company_1/link.txt  \n",
            "   creating: spider/database/college_2/\n",
            "  inflating: spider/database/college_2/TextBookExampleSchema.sql  \n",
            "  inflating: spider/database/college_2/college_2.sqlite  \n",
            " extracting: spider/database/college_2/link.txt  \n",
            "   creating: spider/database/voter_2/\n",
            "  inflating: spider/database/voter_2/schema.sql  \n",
            "  inflating: spider/database/voter_2/voter_2.sqlite  \n",
            "   creating: spider/database/student_assessment/\n",
            "  inflating: spider/database/student_assessment/schema.sql  \n",
            "  inflating: spider/database/student_assessment/student_assessment.sqlite  \n",
            "   creating: spider/database/mountain_photos/\n",
            "  inflating: spider/database/mountain_photos/schema.sql  \n",
            "  inflating: spider/database/mountain_photos/mountain_photos.sqlite  \n",
            "   creating: spider/database/insurance_fnol/\n",
            "  inflating: spider/database/insurance_fnol/schema.sql  \n",
            "  inflating: spider/database/insurance_fnol/insurance_fnol.sqlite  \n",
            "   creating: spider/database/race_track/\n",
            "  inflating: spider/database/race_track/schema.sql  \n",
            "  inflating: spider/database/race_track/race_track.sqlite  \n",
            "   creating: spider/database/body_builder/\n",
            "  inflating: spider/database/body_builder/schema.sql  \n",
            "  inflating: spider/database/body_builder/body_builder.sqlite  \n",
            "   creating: spider/database/tracking_orders/\n",
            "  inflating: spider/database/tracking_orders/tracking_orders.sqlite  \n",
            "  inflating: spider/database/tracking_orders/schema.sql  \n",
            "   creating: spider/database/employee_hire_evaluation/\n",
            "  inflating: spider/database/employee_hire_evaluation/schema.sql  \n",
            "  inflating: spider/database/employee_hire_evaluation/employee_hire_evaluation.sqlite  \n",
            "   creating: spider/database/tracking_share_transactions/\n",
            "  inflating: spider/database/tracking_share_transactions/schema.sql  \n",
            "  inflating: spider/database/tracking_share_transactions/tracking_share_transactions.sqlite  \n",
            "   creating: spider/database/cre_Theme_park/\n",
            "  inflating: spider/database/cre_Theme_park/schema.sql  \n",
            "  inflating: spider/database/cre_Theme_park/cre_Theme_park.sqlite  \n",
            "   creating: spider/database/customers_and_products_contacts/\n",
            "  inflating: spider/database/customers_and_products_contacts/schema.sql  \n",
            "  inflating: spider/database/customers_and_products_contacts/customers_and_products_contacts.sqlite  \n",
            "   creating: spider/database/tracking_grants_for_research/\n",
            "  inflating: spider/database/tracking_grants_for_research/schema.sql  \n",
            "  inflating: spider/database/tracking_grants_for_research/tracking_grants_for_research.sqlite  \n",
            "   creating: spider/database/city_record/\n",
            "  inflating: spider/database/city_record/city_record.sqlite  \n",
            "  inflating: spider/database/city_record/schema.sql  \n",
            "   creating: spider/database/assets_maintenance/\n",
            "  inflating: spider/database/assets_maintenance/schema.sql  \n",
            "  inflating: spider/database/assets_maintenance/assets_maintenance.sqlite  \n",
            "   creating: spider/database/music_4/\n",
            "  inflating: spider/database/music_4/schema.sql  \n",
            "  inflating: spider/database/music_4/music_4.sqlite  \n",
            "   creating: spider/database/wrestler/\n",
            "  inflating: spider/database/wrestler/schema.sql  \n",
            "  inflating: spider/database/wrestler/wrestler.sqlite  \n",
            "   creating: spider/database/customer_complaints/\n",
            "  inflating: spider/database/customer_complaints/schema.sql  \n",
            "  inflating: spider/database/customer_complaints/customer_complaints.sqlite  \n",
            "   creating: spider/database/store_product/\n",
            "  inflating: spider/database/store_product/schema.sql  \n",
            "  inflating: spider/database/store_product/store_product.sqlite  \n",
            "   creating: spider/database/local_govt_mdm/\n",
            "  inflating: spider/database/local_govt_mdm/schema.sql  \n",
            "  inflating: spider/database/local_govt_mdm/local_govt_mdm.sqlite  \n",
            "   creating: spider/database/world_1/\n",
            "  inflating: spider/database/world_1/world_1.sqlite  \n",
            "  inflating: spider/database/world_1/world_1.json  \n",
            "   creating: spider/database/flight_1/\n",
            "  inflating: spider/database/flight_1/flight_1.sqlite  \n",
            "  inflating: spider/database/flight_1/schema.sql  \n",
            "   creating: spider/database/ship_1/\n",
            "  inflating: spider/database/ship_1/schema.sql  \n",
            "  inflating: spider/database/ship_1/ship_1.sqlite  \n",
            "   creating: spider/database/climbing/\n",
            "  inflating: spider/database/climbing/schema.sql  \n",
            "  inflating: spider/database/climbing/climbing.sqlite  \n",
            "   creating: spider/database/game_injury/\n",
            "  inflating: spider/database/game_injury/schema.sql  \n",
            "  inflating: spider/database/game_injury/game_injury.sqlite  \n",
            "   creating: spider/database/school_finance/\n",
            "  inflating: spider/database/school_finance/schema.sql  \n",
            "  inflating: spider/database/school_finance/school_finance.sqlite  \n",
            "   creating: spider/database/game_1/\n",
            "  inflating: spider/database/game_1/schema.sql  \n",
            "  inflating: spider/database/game_1/game_1.sqlite  \n",
            "   creating: spider/database/architecture/\n",
            "  inflating: spider/database/architecture/schema.sql  \n",
            "  inflating: spider/database/architecture/architecture.sqlite  \n",
            "   creating: spider/database/e_government/\n",
            "  inflating: spider/database/e_government/schema.sql  \n",
            "  inflating: spider/database/e_government/e_government.sqlite  \n",
            "   creating: spider/database/college_1/\n",
            "  inflating: spider/database/college_1/TinyCollege.sql  \n",
            "  inflating: spider/database/college_1/college_1.sqlite  \n",
            " extracting: spider/database/college_1/link.txt  \n",
            "   creating: spider/database/tracking_software_problems/\n",
            "  inflating: spider/database/tracking_software_problems/schema.sql  \n",
            "  inflating: spider/database/tracking_software_problems/tracking_software_problems.sqlite  \n",
            "   creating: spider/database/farm/\n",
            "  inflating: spider/database/farm/schema.sql  \n",
            "  inflating: spider/database/farm/farm.sqlite  \n",
            "   creating: spider/database/culture_company/\n",
            "  inflating: spider/database/culture_company/schema.sql  \n",
            "  inflating: spider/database/culture_company/culture_company.sqlite  \n",
            "   creating: spider/database/pilot_record/\n",
            "  inflating: spider/database/pilot_record/schema.sql  \n",
            "  inflating: spider/database/pilot_record/pilot_record.sqlite  \n",
            "   creating: spider/database/school_bus/\n",
            "  inflating: spider/database/school_bus/schema.sql  \n",
            "  inflating: spider/database/school_bus/school_bus.sqlite  \n",
            "   creating: spider/database/inn_1/\n",
            "   creating: spider/database/inn_1/data_csv/\n",
            "  inflating: spider/database/inn_1/data_csv/Rooms.csv  \n",
            "  inflating: spider/database/inn_1/data_csv/README.INN.TXT  \n",
            "  inflating: spider/database/inn_1/data_csv/Reservations_t.csv  \n",
            "  inflating: spider/database/inn_1/data_csv/Reservations.csv  \n",
            "  inflating: spider/database/inn_1/annotation.json  \n",
            "  inflating: spider/database/inn_1/inn_1.sqlite  \n",
            "  inflating: spider/database/inn_1/inn_1.sql  \n",
            "  inflating: spider/database/inn_1/q.txt  \n",
            "  inflating: spider/database/inn_1/change_date.py  \n",
            " extracting: spider/database/inn_1/link.txt  \n",
            "   creating: spider/database/local_govt_and_lot/\n",
            "  inflating: spider/database/local_govt_and_lot/schema.sql  \n",
            "  inflating: spider/database/local_govt_and_lot/local_govt_and_lot.sqlite  \n",
            "   creating: spider/database/aircraft/\n",
            "  inflating: spider/database/aircraft/schema.sql  \n",
            "  inflating: spider/database/aircraft/aircraft.sqlite  \n",
            "   creating: spider/database/real_estate_properties/\n",
            "  inflating: spider/database/real_estate_properties/schema.sql  \n",
            "  inflating: spider/database/real_estate_properties/real_estate_properties.sqlite  \n",
            "   creating: spider/database/music_2/\n",
            "  inflating: spider/database/music_2/schema.sql  \n",
            "  inflating: spider/database/music_2/music_2.sqlite  \n",
            "   creating: spider/database/match_season/\n",
            "  inflating: spider/database/match_season/schema.sql  \n",
            "  inflating: spider/database/match_season/match_season.sqlite  \n",
            "   creating: spider/database/county_public_safety/\n",
            "  inflating: spider/database/county_public_safety/schema.sql  \n",
            "  inflating: spider/database/county_public_safety/county_public_safety.sqlite  \n",
            "   creating: spider/database/network_1/\n",
            "  inflating: spider/database/network_1/schema.sql  \n",
            "  inflating: spider/database/network_1/network_1.sqlite  \n",
            "   creating: spider/database/yelp/\n",
            "  inflating: spider/database/yelp/schema.sql  \n",
            "  inflating: spider/database/yelp/yelp.sqlite  \n",
            "   creating: spider/database/solvency_ii/\n",
            "  inflating: spider/database/solvency_ii/schema.sql  \n",
            "  inflating: spider/database/solvency_ii/solvency_ii.sqlite  \n",
            "   creating: spider/database/singer/\n",
            "  inflating: spider/database/singer/schema.sql  \n",
            "  inflating: spider/database/singer/singer.sqlite  \n",
            "   creating: spider/database/college_3/\n",
            "  inflating: spider/database/college_3/schema.sql  \n",
            "  inflating: spider/database/college_3/college_3.sqlite  \n",
            "   creating: spider/database/movie_1/\n",
            "  inflating: spider/database/movie_1/schema.sql  \n",
            "  inflating: spider/database/movie_1/movie_1.sqlite  \n",
            "   creating: spider/database/twitter_1/\n",
            "  inflating: spider/database/twitter_1/twitter_1.sqlite  \n",
            "   creating: spider/database/twitter_1/queries/\n",
            "  inflating: spider/database/twitter_1/queries/oracle-dialects.xml  \n",
            "  inflating: spider/database/twitter_1/queries/sqlserver-dialects.xml  \n",
            "  inflating: spider/database/twitter_1/queries/postgres-dialects.xml  \n",
            "   creating: spider/database/music_1/\n",
            "  inflating: spider/database/music_1/schema.sql  \n",
            "  inflating: spider/database/music_1/music_1.sqlite  \n",
            "   creating: spider/database/company_employee/\n",
            "  inflating: spider/database/company_employee/schema.sql  \n",
            "  inflating: spider/database/company_employee/company_employee.sqlite  \n",
            "   creating: spider/database/pets_1/\n",
            "  inflating: spider/database/pets_1/schema.sql  \n",
            "  inflating: spider/database/pets_1/pets_1.sqlite  \n",
            "   creating: spider/database/gas_company/\n",
            "  inflating: spider/database/gas_company/schema.sql  \n",
            "  inflating: spider/database/gas_company/gas_company.sqlite  \n",
            "   creating: spider/database/academic/\n",
            "  inflating: spider/database/academic/schema.sql  \n",
            "  inflating: spider/database/academic/academic.sqlite  \n",
            "   creating: spider/database/battle_death/\n",
            "  inflating: spider/database/battle_death/schema.sql  \n",
            "  inflating: spider/database/battle_death/battle_death.sqlite  \n",
            "   creating: spider/database/election_representative/\n",
            "  inflating: spider/database/election_representative/schema.sql  \n",
            "  inflating: spider/database/election_representative/election_representative.sqlite  \n",
            "   creating: spider/database/dog_kennels/\n",
            "  inflating: spider/database/dog_kennels/schema.sql  \n",
            "  inflating: spider/database/dog_kennels/dog_kennels.sqlite  \n",
            "   creating: spider/database/products_for_hire/\n",
            "  inflating: spider/database/products_for_hire/products_for_hire.sqlite  \n",
            "  inflating: spider/database/products_for_hire/schema.sql  \n",
            "   creating: spider/database/e_learning/\n",
            "  inflating: spider/database/e_learning/schema.sql  \n",
            "  inflating: spider/database/e_learning/e_learning.sqlite  \n",
            "   creating: spider/database/entertainment_awards/\n",
            "  inflating: spider/database/entertainment_awards/schema.sql  \n",
            "  inflating: spider/database/entertainment_awards/entertainment_awards.sqlite  \n",
            "   creating: spider/database/tvshow/\n",
            "  inflating: spider/database/tvshow/schema.sql  \n",
            "  inflating: spider/database/tvshow/tvshow.sqlite  \n",
            "   creating: spider/database/theme_gallery/\n",
            "  inflating: spider/database/theme_gallery/schema.sql  \n",
            "  inflating: spider/database/theme_gallery/theme_gallery.sqlite  \n",
            "   creating: spider/database/document_management/\n",
            "  inflating: spider/database/document_management/schema.sql  \n",
            "  inflating: spider/database/document_management/document_management.sqlite  \n",
            "   creating: spider/database/university_basketball/\n",
            "  inflating: spider/database/university_basketball/schema.sql  \n",
            "  inflating: spider/database/university_basketball/university_basketball.sqlite  \n",
            "   creating: spider/database/orchestra/\n",
            "  inflating: spider/database/orchestra/schema.sql  \n",
            "  inflating: spider/database/orchestra/orchestra.sqlite  \n",
            "   creating: spider/database/restaurants/\n",
            "  inflating: spider/database/restaurants/schema.sql  \n",
            "  inflating: spider/database/restaurants/restaurants.sqlite  \n",
            "   creating: spider/database/flight_2/\n",
            "   creating: spider/database/flight_2/data_csv/\n",
            "  inflating: spider/database/flight_2/data_csv/README.AIRLINES.txt  \n",
            "  inflating: spider/database/flight_2/data_csv/airports100.csv  \n",
            "  inflating: spider/database/flight_2/data_csv/airlines.csv  \n",
            "  inflating: spider/database/flight_2/data_csv/flights.csv  \n",
            "  inflating: spider/database/flight_2/annotation.json  \n",
            "  inflating: spider/database/flight_2/flight_2.sql  \n",
            "  inflating: spider/database/flight_2/flight_2.json  \n",
            "  inflating: spider/database/flight_2/flight_2.sqlite  \n",
            "  inflating: spider/database/flight_2/q.txt  \n",
            " extracting: spider/database/flight_2/link.txt  \n",
            "   creating: spider/database/student_1/\n",
            "   creating: spider/database/student_1/data_csv/\n",
            "  inflating: spider/database/student_1/data_csv/README.STUDENTS.TXT  \n",
            "  inflating: spider/database/student_1/data_csv/list.csv  \n",
            "  inflating: spider/database/student_1/data_csv/teachers.csv  \n",
            "  inflating: spider/database/student_1/annotation.json  \n",
            "  inflating: spider/database/student_1/student_1.sql  \n",
            "  inflating: spider/database/student_1/student_1.sqlite  \n",
            "  inflating: spider/database/student_1/q.txt  \n",
            " extracting: spider/database/student_1/link.txt  \n",
            "   creating: spider/database/party_host/\n",
            "  inflating: spider/database/party_host/schema.sql  \n",
            "  inflating: spider/database/party_host/party_host.sqlite  \n",
            "   creating: spider/database/epinions_1/\n",
            "  inflating: spider/database/epinions_1/epinions_1.sqlite  \n",
            "   creating: spider/database/wedding/\n",
            "  inflating: spider/database/wedding/schema.sql  \n",
            "  inflating: spider/database/wedding/wedding.sqlite  \n",
            "   creating: spider/database/department_management/\n",
            "  inflating: spider/database/department_management/schema.sql  \n",
            "  inflating: spider/database/department_management/department_management.sqlite  \n",
            "   creating: spider/database/products_gen_characteristics/\n",
            "  inflating: spider/database/products_gen_characteristics/schema.sql  \n",
            "  inflating: spider/database/products_gen_characteristics/products_gen_characteristics.sqlite  \n",
            "   creating: spider/database/riding_club/\n",
            "  inflating: spider/database/riding_club/schema.sql  \n",
            "  inflating: spider/database/riding_club/riding_club.sqlite  \n",
            "   creating: spider/database/loan_1/\n",
            "  inflating: spider/database/loan_1/schema.sql  \n",
            "  inflating: spider/database/loan_1/loan_1.sqlite  \n",
            "   creating: spider/database/small_bank_1/\n",
            "  inflating: spider/database/small_bank_1/small_bank_1.sqlite  \n",
            "   creating: spider/database/flight_company/\n",
            "  inflating: spider/database/flight_company/schema.sql  \n",
            "  inflating: spider/database/flight_company/flight_company.sqlite  \n",
            "   creating: spider/database/manufactory_1/\n",
            "  inflating: spider/database/manufactory_1/schema.sql  \n",
            "  inflating: spider/database/manufactory_1/manufactory_1.sqlite  \n",
            "   creating: spider/database/customers_and_addresses/\n",
            "  inflating: spider/database/customers_and_addresses/schema.sql  \n",
            "  inflating: spider/database/customers_and_addresses/customers_and_addresses.sqlite  \n",
            "   creating: spider/database/station_weather/\n",
            "  inflating: spider/database/station_weather/schema.sql  \n",
            "  inflating: spider/database/station_weather/station_weather.sqlite  \n",
            "   creating: spider/database/manufacturer/\n",
            "  inflating: spider/database/manufacturer/schema.sql  \n",
            "  inflating: spider/database/manufacturer/manufacturer.sqlite  \n",
            "   creating: spider/database/phone_market/\n",
            "  inflating: spider/database/phone_market/schema.sql  \n",
            "  inflating: spider/database/phone_market/phone_market.sqlite  \n",
            "   creating: spider/database/wta_1/\n",
            "  inflating: spider/database/wta_1/wta_1.sql  \n",
            "  inflating: spider/database/wta_1/wta_1.sqlite  \n",
            "   creating: spider/database/perpetrator/\n",
            "  inflating: spider/database/perpetrator/schema.sql  \n",
            "  inflating: spider/database/perpetrator/perpetrator.sqlite  \n",
            "   creating: spider/database/train_station/\n",
            "  inflating: spider/database/train_station/schema.sql  \n",
            "  inflating: spider/database/train_station/train_station.sqlite  \n",
            "   creating: spider/database/medicine_enzyme_interaction/\n",
            "  inflating: spider/database/medicine_enzyme_interaction/schema.sql  \n",
            "  inflating: spider/database/medicine_enzyme_interaction/medicine_enzyme_interaction.sqlite  \n",
            "   creating: spider/database/chinook_1/\n",
            "  inflating: spider/database/chinook_1/annotation.json  \n",
            "  inflating: spider/database/chinook_1/chinook_1.sqlite  \n",
            "   creating: spider/database/driving_school/\n",
            "  inflating: spider/database/driving_school/schema.sql  \n",
            "  inflating: spider/database/driving_school/driving_school.sqlite  \n",
            "   creating: spider/database/news_report/\n",
            "  inflating: spider/database/news_report/schema.sql  \n",
            "  inflating: spider/database/news_report/news_report.sqlite  \n",
            "   creating: spider/database/icfp_1/\n",
            "  inflating: spider/database/icfp_1/icfp_1.sqlite  \n",
            "  inflating: spider/database/icfp_1/q.txt  \n",
            "  inflating: spider/database/icfp_1/link.txt  \n",
            "   creating: spider/database/cre_Doc_Tracking_DB/\n",
            "  inflating: spider/database/cre_Doc_Tracking_DB/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Tracking_DB/cre_Doc_Tracking_DB.sqlite  \n",
            "   creating: spider/database/behavior_monitoring/\n",
            "  inflating: spider/database/behavior_monitoring/schema.sql  \n",
            "  inflating: spider/database/behavior_monitoring/behavior_monitoring.sqlite  \n",
            "   creating: spider/database/restaurant_1/\n",
            "  inflating: spider/database/restaurant_1/schema.sql  \n",
            "  inflating: spider/database/restaurant_1/restaurant_1.sqlite  \n",
            "   creating: spider/database/scholar/\n",
            "  inflating: spider/database/scholar/schema.sql  \n",
            "  inflating: spider/database/scholar/scholar.sqlite  \n",
            "   creating: spider/database/product_catalog/\n",
            "  inflating: spider/database/product_catalog/schema.sql  \n",
            "  inflating: spider/database/product_catalog/product_catalog.sqlite  \n",
            "   creating: spider/database/csu_1/\n",
            "  inflating: spider/database/csu_1/schema.sql  \n",
            "  inflating: spider/database/csu_1/csu_1.sqlite  \n",
            "   creating: spider/database/debate/\n",
            "  inflating: spider/database/debate/schema.sql  \n",
            "  inflating: spider/database/debate/debate.sqlite  \n",
            "   creating: spider/database/railway/\n",
            "  inflating: spider/database/railway/schema.sql  \n",
            "  inflating: spider/database/railway/railway.sqlite  \n",
            "   creating: spider/database/protein_institute/\n",
            "  inflating: spider/database/protein_institute/schema.sql  \n",
            "  inflating: spider/database/protein_institute/protein_institute.sqlite  \n",
            "   creating: spider/database/machine_repair/\n",
            "  inflating: spider/database/machine_repair/schema.sql  \n",
            "  inflating: spider/database/machine_repair/machine_repair.sqlite  \n",
            "   creating: spider/database/insurance_and_eClaims/\n",
            "  inflating: spider/database/insurance_and_eClaims/schema.sql  \n",
            "  inflating: spider/database/insurance_and_eClaims/insurance_and_eClaims.sqlite  \n",
            "   creating: spider/database/museum_visit/\n",
            "  inflating: spider/database/museum_visit/museum_visit.sqlite  \n",
            "  inflating: spider/database/museum_visit/schema.sql  \n",
            "   creating: spider/database/wine_1/\n",
            "   creating: spider/database/wine_1/data_csv/\n",
            "  inflating: spider/database/wine_1/data_csv/appellations.csv  \n",
            "  inflating: spider/database/wine_1/data_csv/grapes.csv  \n",
            "  inflating: spider/database/wine_1/data_csv/wine.csv  \n",
            "  inflating: spider/database/wine_1/data_csv/README.WINE.txt  \n",
            "  inflating: spider/database/wine_1/annotation.json  \n",
            "  inflating: spider/database/wine_1/wine_1.sqlite  \n",
            "  inflating: spider/database/wine_1/wine_1.sql  \n",
            "   creating: spider/database/wine_1/.ipynb_checkpoints/\n",
            "  inflating: spider/database/wine_1/q.txt  \n",
            " extracting: spider/database/wine_1/link.txt  \n",
            "   creating: spider/database/swimming/\n",
            "  inflating: spider/database/swimming/schema.sql  \n",
            "  inflating: spider/database/swimming/swimming.sqlite  \n",
            "   creating: spider/database/election/\n",
            "  inflating: spider/database/election/election.sqlite  \n",
            "  inflating: spider/database/election/schema.sql  \n",
            "   creating: spider/database/dorm_1/\n",
            "  inflating: spider/database/dorm_1/schema.sql  \n",
            "  inflating: spider/database/dorm_1/dorm_1.sqlite  \n",
            "   creating: spider/database/course_teach/\n",
            "  inflating: spider/database/course_teach/schema.sql  \n",
            "  inflating: spider/database/course_teach/course_teach.sqlite  \n",
            "   creating: spider/database/club_1/\n",
            "  inflating: spider/database/club_1/schema.sql  \n",
            "  inflating: spider/database/club_1/club_1.sqlite  \n",
            "   creating: spider/database/concert_singer/\n",
            "  inflating: spider/database/concert_singer/schema.sql  \n",
            "  inflating: spider/database/concert_singer/concert_singer.sqlite  \n",
            "   creating: spider/database/sakila_1/\n",
            "  inflating: spider/database/sakila_1/schema.sql  \n",
            "  inflating: spider/database/sakila_1/sakila_1.sqlite  \n",
            "   creating: spider/database/customers_card_transactions/\n",
            "  inflating: spider/database/customers_card_transactions/schema.sql  \n",
            "  inflating: spider/database/customers_card_transactions/customers_card_transactions.sqlite  \n",
            "   creating: spider/database/poker_player/\n",
            "  inflating: spider/database/poker_player/schema.sql  \n",
            "  inflating: spider/database/poker_player/poker_player.sqlite  \n",
            "   creating: spider/database/customers_and_invoices/\n",
            "  inflating: spider/database/customers_and_invoices/schema.sql  \n",
            "  inflating: spider/database/customers_and_invoices/customers_and_invoices.sqlite  \n",
            "   creating: spider/database/musical/\n",
            "  inflating: spider/database/musical/schema.sql  \n",
            "  inflating: spider/database/musical/musical.sqlite  \n",
            "   creating: spider/database/sports_competition/\n",
            "  inflating: spider/database/sports_competition/schema.sql  \n",
            "  inflating: spider/database/sports_competition/sports_competition.sqlite  \n",
            "   creating: spider/database/network_2/\n",
            "  inflating: spider/database/network_2/network_2.sqlite  \n",
            "  inflating: spider/database/network_2/schema.sql  \n",
            "   creating: spider/database/geo/\n",
            "  inflating: spider/database/geo/schema.sql  \n",
            "  inflating: spider/database/geo/geo.sqlite  \n",
            "   creating: spider/database/party_people/\n",
            "  inflating: spider/database/party_people/schema.sql  \n",
            "  inflating: spider/database/party_people/party_people.sqlite  \n",
            "   creating: spider/database/cinema/\n",
            "  inflating: spider/database/cinema/schema.sql  \n",
            "  inflating: spider/database/cinema/cinema.sqlite  \n",
            "   creating: spider/database/baseball_1/\n",
            "  inflating: spider/database/baseball_1/schema.sql  \n",
            "  inflating: spider/database/baseball_1/baseball_1.sqlite  \n",
            "   creating: spider/database/book_2/\n",
            "  inflating: spider/database/book_2/schema.sql  \n",
            "  inflating: spider/database/book_2/book_2.sqlite  \n",
            "  inflating: spider/dev.json         \n",
            "  inflating: spider/train_others.json  \n",
            "  inflating: spider/.DS_Store        \n",
            "  inflating: spider/dev_gold.sql     \n",
            "  inflating: spider/train_spider.json  \n",
            "  inflating: spider/train_gold.sql   \n",
            "  inflating: spider/README.txt       \n",
            "  inflating: spider/tables.json      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7ahJ2aJE4jK",
        "outputId": "a115e248-0a4e-4758-a717-b32fa093d6ad"
      },
      "source": [
        "!pip install attrs\n",
        "!bash data/spider/generate.sh ./spider"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (21.2.0)\n",
            "Procesing train_others\n",
            "100% 1659/1659 [00:00<00:00, 3192.69it/s]\n",
            "\n",
            "Procesing train_spider\n",
            "patching file train_spider.json\n",
            "Hunk #1 succeeded at 436215 (offset 7025 lines).\n",
            "Hunk #2 succeeded at 436231 (offset 7025 lines).\n",
            "Hunk #3 succeeded at 436259 (offset 7025 lines).\n",
            "100% 7000/7000 [00:01<00:00, 4130.31it/s]\n",
            "\n",
            "Procesing dev\n",
            "100% 1034/1034 [00:00<00:00, 4298.99it/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbZ7cPAJE9_3"
      },
      "source": [
        "!mkdir data/spider-bart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtnYfCnHFDev"
      },
      "source": [
        "!cp ./spider/tables.json data/spider-bart/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oq7sQG-FM_w"
      },
      "source": [
        "!cp ./spider/train_spider.json data/spider-bart/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxrX_vuVFPGw"
      },
      "source": [
        "!cp ./spider/train_others.json data/spider-bart/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7gPaFlZFQ9f"
      },
      "source": [
        "!cp ./spider/dev.json data/spider-bart/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VryFosJFSfP"
      },
      "source": [
        "!ln -s $(pwd)/spider/database data/spider-bart/database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFvOF_utFU9X"
      },
      "source": [
        "!mkdir third_party"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLFHEW3ZFZQL",
        "outputId": "1fcba7db-be34-4484-a80a-69a1d924ec6f"
      },
      "source": [
        "!wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-01 00:02:24--  http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip [following]\n",
            "--2021-07-01 00:02:24--  https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2018-10-05.zip [following]\n",
            "--2021-07-01 00:02:24--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2018-10-05.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 393239982 (375M) [application/zip]\n",
            "Saving to: ‘stanford-corenlp-full-2018-10-05.zip’\n",
            "\n",
            "stanford-corenlp-fu 100%[===================>] 375.02M  5.07MB/s    in 71s     \n",
            "\n",
            "2021-07-01 00:03:36 (5.25 MB/s) - ‘stanford-corenlp-full-2018-10-05.zip’ saved [393239982/393239982]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2G1pwx7FbSv",
        "outputId": "d50036ec-c5bb-4bf9-f9e7-3f0abd4194ba"
      },
      "source": [
        "!unzip stanford-corenlp-full-2018-10-05.zip -d third_party/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  stanford-corenlp-full-2018-10-05.zip\n",
            "   creating: third_party/stanford-corenlp-full-2018-10-05/\n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/jaxb-core-2.3.0.1-sources.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/xom-1.2.10-src.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/CoreNLP-to-HTML.xsl  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/README.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/jollyday-0.4.9-sources.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/LIBRARY-LICENSES  \n",
            "   creating: third_party/stanford-corenlp-full-2018-10-05/sutime/\n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/sutime/british.sutime.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/sutime/defs.sutime.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/sutime/spanish.sutime.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/sutime/english.sutime.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/sutime/english.holidays.sutime.txt  \n",
            " extracting: third_party/stanford-corenlp-full-2018-10-05/ejml-0.23-src.zip  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/input.txt.xml  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/build.xml  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/pom.xml  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-javadoc.jar  \n",
            "   creating: third_party/stanford-corenlp-full-2018-10-05/tokensregex/\n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/tokensregex/color.input.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/tokensregex/retokenize.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/tokensregex/color.properties  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/tokensregex/color.rules.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/javax.json-api-1.0-sources.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/jaxb-api-2.4.0-b180830.0359-sources.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-models.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/protobuf.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/javax.activation-api-1.2.0.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/StanfordDependenciesManual.pdf  \n",
            "   creating: third_party/stanford-corenlp-full-2018-10-05/patterns/\n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/patterns/example.properties  \n",
            " extracting: third_party/stanford-corenlp-full-2018-10-05/patterns/otherpeople.txt  \n",
            " extracting: third_party/stanford-corenlp-full-2018-10-05/patterns/goldplaces.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/patterns/stopwords.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/patterns/presidents.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/patterns/names.txt  \n",
            " extracting: third_party/stanford-corenlp-full-2018-10-05/patterns/places.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/patterns/goldnames.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/slf4j-simple.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-sources.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/input.txt  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/joda-time.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/xom.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/jaxb-impl-2.4.0-b180830.0438-sources.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/StanfordCoreNlpDemo.java  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/jaxb-core-2.3.0.1.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/RESOURCE-LICENSES  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/javax.activation-api-1.2.0-sources.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/slf4j-api.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/pom-java-11.xml  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/ejml-0.23.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/javax.json.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/Makefile  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/corenlp.sh  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/joda-time-2.9-sources.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/jaxb-api-2.4.0-b180830.0359.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/jollyday.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/ShiftReduceDemo.java  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/jaxb-impl-2.4.0-b180830.0438.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2.jar  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/SemgrexDemo.java  \n",
            "  inflating: third_party/stanford-corenlp-full-2018-10-05/LICENSE.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjTGn0xRFm1x",
        "outputId": "b51e0b5f-ea8e-42fe-d2ad-3adec6f33aa5"
      },
      "source": [
        "!pushd third_party/stanford-corenlp-full-2018-10-05\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gap-text2sql/rat-sql-gap/third_party/stanford-corenlp-full-2018-10-05 /content/gap-text2sql/rat-sql-gap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pf6BxnRFyXt",
        "outputId": "d1aea440-ac8b-4162-cc1b-624036eb76a4"
      },
      "source": [
        "!nohup java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 8999 -timeout 15000 > server.log &\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nohup: redirecting stderr to stdout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtuq47ukF09u",
        "outputId": "3089404c-2d60-417e-f68a-39896c75bd50"
      },
      "source": [
        "!popd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: popd: directory stack empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSt85XjSF3mO"
      },
      "source": [
        "!mkdir -p logdir/bart_run_1/bs\\=12\\,lr\\=1.0e-04\\,bert_lr\\=1.0e-05\\,end_lr\\=0e0\\,att\\=1/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUJCWq1BF6cY"
      },
      "source": [
        "!mkdir ie_dirs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbef1WzvF75u"
      },
      "source": [
        "!mkdir -p pretrained_checkpoint\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6hi7aXhF92m",
        "outputId": "f8074904-5705-4df3-ddb6-224c97a894d2"
      },
      "source": [
        "!curl https://gap-text2sql-public.s3.amazonaws.com/checkpoint-artifacts/gap-finetuned-checkpoint -o logdir/bart_run_1/bs\\=12\\,lr\\=1.0e-04\\,bert_lr\\=1.0e-05\\,end_lr\\=0e0\\,att\\=1/model_checkpoint-00041000\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3629M  100 3629M    0     0  32.9M      0  0:01:50  0:01:50 --:--:-- 31.8M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbCgaflDF_Un",
        "outputId": "8808451d-a147-49dc-8594-ef672d62e5f9"
      },
      "source": [
        "!curl https://gap-text2sql-public.s3.amazonaws.com/checkpoint-artifacts/pretrained-checkpoint -o pretrained_checkpoint/pytorch_model.bin\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2335M  100 2335M    0     0  31.3M      0  0:01:14  0:01:14 --:--:-- 28.7M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bynabC88Hl6m",
        "outputId": "1aa5a6bf-076a-489f-8b50-0ce3d0feb057"
      },
      "source": [
        "!pip install asdl\n",
        "!python run.py preprocess experiments/spider-configs/gap-run.jsonnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting asdl\n",
            "  Downloading https://files.pythonhosted.org/packages/76/5d/c8db2502e56ba60ccab83f60d19dffa418dd0a289dfd6e00a402864ef2b3/asdl-0.1.5.tar.gz\n",
            "Building wheels for collected packages: asdl\n",
            "  Building wheel for asdl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asdl: filename=asdl-0.1.5-cp37-none-any.whl size=9925 sha256=ef6b23333dde2b50fd9d7ccbebebfc4ff34e1eb662088e37d636a66debf9c940\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/61/1a/f01c1941280ed8811a54a42153bf21d203586c28e43b5138dc\n",
            "Successfully built asdl\n",
            "Installing collected packages: asdl\n",
            "Successfully installed asdl-0.1.5\n",
            "2021-07-01 00:06:52.685865: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "WARNING <class 'seq2struct.models.enc_dec.EncDecModel.Preproc'>: superfluous {'name': 'EncDec'}\n",
            "Downloading: 100% 899k/899k [00:00<00:00, 22.1MB/s]\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 14.2MB/s]\n",
            "train:   0% 0/8659 [00:00<?, ?it/s]The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
            "train: 100% 8659/8659 [35:46<00:00,  4.03it/s]\n",
            "val: 100% 1034/1034 [12:21<00:00,  1.39it/s]\n",
            "Exception ignored in: <function CoreNLP.__del__ at 0x7f69e8928ef0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gap-text2sql/rat-sql-gap/seq2struct/resources/corenlp.py\", line 23, in __del__\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/corenlp/client.py\", line 83, in stop\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1790, in kill\n",
            "AttributeError: 'NoneType' object has no attribute 'SIGKILL'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLnzZeBaGs_Y"
      },
      "source": [
        "# gap-text2sql"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xh2tcyWyGBYv"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import _jsonnet\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZVjaxZpMGh9W"
      },
      "source": [
        "\n",
        "from seq2struct.commands.infer import Inferer\n",
        "from seq2struct.datasets.spider import SpiderItem\n",
        "from seq2struct.utils import registry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EidxuJzMHfSm",
        "outputId": "cb654f2b-b2cb-4458-9b9c-807c98d16960"
      },
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7Fm8MIagICEb"
      },
      "source": [
        "import torch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_rEG2aO1NLEP"
      },
      "source": [
        "exp_config = json.loads(\n",
        "    _jsonnet.evaluate_file(\n",
        "        \"experiments/spider-configs/gap-run.jsonnet\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gEcFyx1MNNN4"
      },
      "source": [
        "model_config_path = exp_config[\"model_config\"]\n",
        "model_config_args = exp_config.get(\"model_config_args\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wnpDvbJ9NOvg"
      },
      "source": [
        "\n",
        "infer_config = json.loads(\n",
        "    _jsonnet.evaluate_file(\n",
        "        model_config_path, \n",
        "        tla_codes={'args': json.dumps(model_config_args)}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3sjaxyu2NRFQ"
      },
      "source": [
        "infer_config[\"model\"][\"encoder_preproc\"][\"db_path\"] = \"data/sqlite_files/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1xJwI9FiNSug",
        "outputId": "90ec0303-9d7b-489b-cb31-fddd5cb14322"
      },
      "source": [
        "inferer = Inferer(infer_config)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING <class 'seq2struct.models.enc_dec.EncDecModel.Preproc'>: superfluous {'name': 'EncDec'}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FJONthcDNT7T"
      },
      "source": [
        "model_dir = exp_config[\"logdir\"] + \"/bs=12,lr=1.0e-04,bert_lr=1.0e-05,end_lr=0e0,att=1\"\n",
        "checkpoint_step = exp_config[\"eval_steps\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "4bf9cf8fe5234a4f8861219329a86aec",
            "5e7251c3315443718b20bcb2959825f1"
          ]
        },
        "id": "L-FTeYyuA3ly",
        "outputId": "c7e42c7d-9893-45c1-d9d5-3b2a96639eb4"
      },
      "source": [
        "model = inferer.load_model(model_dir, checkpoint_step)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING <class 'seq2struct.models.enc_dec.EncDecModel'>: superfluous {'decoder_preproc': {'grammar': {'clause_order': None, 'end_with_from': True, 'factorize_sketch': 2, 'include_literals': False, 'infer_from_conditions': True, 'name': 'spider', 'output_from': True, 'use_table_pointer': True}, 'save_path': 'data/spider-bart/nl2code-1115,output_from=true,fs=2,emb=bart,cvlink', 'use_seq_elem_rules': True}, 'encoder_preproc': {'bart_version': 'facebook/bart-large', 'compute_cv_link': True, 'compute_sc_link': True, 'db_path': 'data/sqlite_files/', 'fix_issue_16_primary_keys': True, 'include_table_name_in_column': False, 'save_path': 'data/spider-bart/nl2code-1115,output_from=true,fs=2,emb=bart,cvlink'}}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bf9cf8fe5234a4f8861219329a86aec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1525.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e7251c3315443718b20bcb2959825f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1018571383.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parameter containing:\n",
            "tensor([[-0.0370,  0.1117,  0.1829,  ...,  0.2054,  0.0578, -0.0750],\n",
            "        [ 0.0055, -0.0049, -0.0069,  ..., -0.0030,  0.0038,  0.0087],\n",
            "        [-0.0448,  0.4604, -0.0604,  ...,  0.1073,  0.0310,  0.0477],\n",
            "        ...,\n",
            "        [-0.0138,  0.0278, -0.0467,  ...,  0.0455, -0.0265,  0.0125],\n",
            "        [-0.0043,  0.0153, -0.0567,  ...,  0.0496,  0.0108, -0.0099],\n",
            "        [ 0.0053,  0.0324, -0.0179,  ..., -0.0085,  0.0223, -0.0020]],\n",
            "       requires_grad=True)\n",
            "Updated the model with ./pretrained_checkpoint/pytorch_model.bin\n",
            "Parameter containing:\n",
            "tensor([[-3.8313e-02,  1.2050e-01,  1.7760e-01,  ...,  1.9729e-01,\n",
            "          5.9443e-02, -6.9929e-02],\n",
            "        [ 4.5650e-03, -2.3032e-03, -8.4326e-03,  ..., -3.5686e-03,\n",
            "          4.7121e-03,  8.4110e-03],\n",
            "        [-4.5997e-02,  4.6710e-01, -6.5000e-02,  ...,  1.0271e-01,\n",
            "          2.5631e-02,  4.7501e-02],\n",
            "        ...,\n",
            "        [ 1.9880e-02, -3.9793e-02, -2.7116e-02,  ...,  2.1493e-02,\n",
            "         -1.5526e-02, -1.9425e-02],\n",
            "        [-2.4527e-02,  1.2546e-04,  3.3096e-02,  ...,  1.3423e-02,\n",
            "          1.6690e-02,  1.5640e-02],\n",
            "        [ 1.5354e-02, -1.0395e-02,  1.2477e-02,  ..., -3.0579e-02,\n",
            "         -1.5324e-02, -2.9205e-03]], requires_grad=True)\n",
            "Loading model from logdir/bart_run_1/bs=12,lr=1.0e-04,bert_lr=1.0e-05,end_lr=0e0,att=1/model_checkpoint-00041000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4tj_kgJQCgEb"
      },
      "source": [
        "from seq2struct.datasets.spider_lib.preprocess.get_tables import dump_db_json_schema\n",
        "from seq2struct.datasets.spider import load_tables_from_schema_dict\n",
        "db_id = \"singer\"\n",
        "my_schema = dump_db_json_schema(\"data/sqlite_files/{db_id}/{db_id}.sqlite\".format(db_id=db_id), db_id)\n",
        "from seq2struct.utils.api_utils import refine_schema_names\n",
        "my_schema\n",
        "\n",
        "\n",
        "schema, eval_foreign_key_maps = load_tables_from_schema_dict(my_schema)\n",
        "dataset = registry.construct('dataset_infer', {\n",
        "   \"name\": \"spider\", \"schemas\": schema, \"eval_foreign_key_maps\": eval_foreign_key_maps, \n",
        "    \"db_path\": \"data/sqlite_files/\"\n",
        "})\n",
        "for _, schema in dataset.schemas.items():\n",
        "    model.preproc.enc_preproc._preprocess_schema(schema)\n",
        "spider_schema = dataset.schemas[db_id]\n",
        "def infer(question):\n",
        "    data_item = SpiderItem(\n",
        "            text=None,  # intentionally None -- should be ignored when the tokenizer is set correctly\n",
        "            code=None,\n",
        "            schema=spider_schema,\n",
        "            orig_schema=spider_schema.orig,\n",
        "            orig={\"question\": question}\n",
        "        )\n",
        "    model.preproc.clear_items()\n",
        "    enc_input = model.preproc.enc_preproc.preprocess_item(data_item, None)\n",
        "    preproc_data = enc_input, None\n",
        "    with torch.no_grad():\n",
        "        output = inferer._infer_one(model, data_item, preproc_data, beam_size=1, use_heuristic=True)\n",
        "    return output[0][\"inferred_code\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_xXt1LhNLgX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "da474c54-0d4f-4cd1-f1e0-df499b5f9026"
      },
      "source": [
        "infer('how many unique singer are there?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SELECT Count(*) FROM singer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "kZFrkJ4yqDBP",
        "outputId": "c935fea9-35a4-43c3-b21d-2a59cc2d5f6c"
      },
      "source": [
        "infer('show the name if the singer that has the largest net worth millions')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SELECT singer.Name FROM singer ORDER BY singer.Net_Worth_Millions Desc LIMIT 1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "hFSMZVfqSylG",
        "outputId": "55ac52a4-6b17-4ad3-d7ab-db18d756724c"
      },
      "source": [
        "infer('who sing the song call on me?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"SELECT singer.Name FROM singer JOIN song WHERE song.Title = 'terminal'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAYuXTsPS8zf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}